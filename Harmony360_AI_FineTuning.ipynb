{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rdntmsn/csvtopdf/blob/master/Harmony360_AI_FineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: set global variables for this project\n",
        "\n",
        "PROJECT_ID = \"your-project-id\" #@param {type:\"string\"}\n",
        "BUCKET_NAME = \"your-bucket-name\" #@param {type:\"string\"}\n",
        "REGION = \"us-central1\" #@param {type:\"string\"}\n",
        "DATASET_ID = \"your_dataset_id\" #@param {type:\"string\"}\n",
        "TABLE_ID = \"your_table_id\" #@param {type:\"string\"}\n",
        "MODEL_NAME = \"your_model_name\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "# Replace with your actual values\n",
        "# You can also set these variables in the environment\n",
        "# or use a secrets management service for production."
      ],
      "metadata": {
        "id": "-pQyfYffpmyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znytEw_v9MPR"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets accelerate --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1OnCL4d8xXpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmRkRSRP-2mr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c63b9c-822a-45c5-e586-ad9c501da6c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtAnPEQt-bwp",
        "outputId": "d7cb1412-4fae-405d-da14-58c209e467d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "{\"instruction\": \"Calculate the Time Node Jump for Gold using Harmony360 principles.\", \"input\": \"Atomic Number: 79 (Au)\", \"output\": \"\\u0394T = (\\u03c6\\u03c0)^79 \\u2248 4.38e+34\"}\n",
            "{\"instruction\": \"Classify the resonance group of Carbon based on Harmony360.\", \"input\": \"Atomic Number: 6 (C)\", \"output\": \"Resonance Group: Quantum Harmonics\"}\n",
            "{\"instruction\": \"Generate the 3\\u20136\\u20139 resonance function for Hydrogen.\", \"input\": \"Atomic Number: 1\", \"output\": \"R_369(\\u03b8) = sin(3) + cos(6) + sin(9) \\u2248 0.4121\"}\n",
            "{\"instruction\": \"What is the \\u03c0-\\u03c6 harmonic alignment of Atomic Number 47?\", \"input\": \"Element: Silver (Ag)\", \"output\": \"Alignment = ((\\u03c6 \\u00d7 47) % \\u03c0) / \\u03c0 \\u2248 0.63321\"}\n",
            "{\"instruction\": \"Simulate a fractal harmonic energy output for Iron using Harmony360.\", \"input\": \"Element: Fe (Atomic Number 26)\", \"output\": \"FHM(x, y) = [sin(3x \\u00d7 1.618) + cos(6\\u03c0y)] / 2\"}\n",
            "{\"instruction\": \"What is the consciousness value at time t=10 using the C360 model?\", \"input\": \"f_b(t) = 8Hz, g_s(t) = 0.77, r_h(t) = sin(3\\u03c0t), t = 10\", \"output\": \"C_360(10) = \\u222b f_b(t)\\u00b7g_s(t)\\u00b7r_h(t) dt \\u2248 -19.38\"}\n",
            "{\"instruction\": \"Predict the output of the AI energy transfer function at t = 30.\", \"input\": \"E = 100, f = 12, T = 60\", \"output\": \"P(30) = 100 \\u00d7 R_369(12) \\u00d7 cos(\\u03c0) \\u2248 -100 \\u00d7 R_369(12)\"}\n",
            "{\"instruction\": \"Is Uranium (U) part of the Noble Harmonics resonance group?\", \"input\": \"Atomic Number: 92\", \"output\": \"No. Resonance Group: Phi-Scaled Resonants\"}\n",
            "{\"instruction\": \"Estimate the quantum resonance stability of Neon.\", \"input\": \"Atomic Number: 10 (Ne)\", \"output\": \"QRS = e^(-10/100) \\u00d7 cos(2\\u03c0 \\u00d7 10 / 360) \\u2248 0.9005\"}\n",
            "{\"instruction\": \"Explain the significance of the number 3 in Harmony360.\", \"input\": \"Mathematical foundation\", \"output\": \"The number 3 is a base harmonic in the R_369 model: sin(3\\u03b8) defines the fundamental oscillation phase.\"}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Now you can access files in your Drive using the path '/content/drive/My Drive/'\n",
        "with open('/content/drive/MyDrive/Harmony360/harmony360_mock_training_dataset.jsonl', 'r') as f:\n",
        "  file_contents = f.read()\n",
        "\n",
        "# Process the contents of the file here\n",
        "print(file_contents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMtWjFY8Euj0"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=\"/content/drive/MyDrive/Harmony360/harmony360_mock_training_dataset.jsonl\", split=\"train\")\n",
        "dataset = dataset.map(lambda x: {\"text\": f\"### Instruction:\\n{x['instruction']}\\n\\n### Input:\\n{x['input']}\\n\\n### Output:\\n{x['output']}\"})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6h2c5W2HFHlR"
      },
      "outputs": [],
      "source": [
        "model_name = \"EleutherAI/gpt-neo-1.3B\"  # You can also try distilGPT2 for lighter training\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOA8hsMjFmQx"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ Load Pretrained Model & Tokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"gpt2\"  # or another base model you're fine-tuning\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# ‚úÖ Fix padding token issue for GPT-style models\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.resize_token_embeddings(len(tokenizer))  # Resize model embedding matrix to include pad token\n",
        "model.config.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# ‚úÖ Tokenizer Function\n",
        "def tokenize(example):\n",
        "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DI3igTKpRr8o"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = dataset.map(tokenize, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unqr4un1R8j2",
        "outputId": "32a2d167-648e-41fd-e8df-67fd74014a5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-4b182e0cd981>:22: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "# ‚úÖ Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./harmony360-model\",\n",
        "    per_device_train_batch_size=2,\n",
        "    num_train_epochs=4,\n",
        "    logging_steps=10,\n",
        "    save_steps=100,\n",
        "    fp16=torch.cuda.is_available(),  # Requires torch import\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "# ‚úÖ Data Collator (no masked language modeling)\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n",
        "\n",
        "# ‚úÖ Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "C6jtGMSMRw5k",
        "outputId": "f63b1e0a-62d3-4610-cb38-5a2f0eaebc3b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-3435b262f1ae>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2558\u001b[0m                     )\n\u001b[1;32m   2559\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2560\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2562\u001b[0m                     if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3735\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3736\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3799\u001b[0m                 \u001b[0mloss_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3800\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3801\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3802\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1060\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m         transformer_outputs = self.transformer(\n\u001b[0m\u001b[1;32m   1063\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m             \u001b[0mpast_key_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    920\u001b[0m                 )\n\u001b[1;32m    921\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 outputs = block(\n\u001b[0m\u001b[1;32m    923\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         attn_outputs = self.attn(\n\u001b[0m\u001b[1;32m    405\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/gpt2/modeling_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m             )\n\u001b[1;32m    334\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             attn_output, attn_weights = attention_interface(\n\u001b[0m\u001b[1;32m    336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/integrations/sdpa_attention.py\u001b[0m in \u001b[0;36msdpa_attention_forward\u001b[0;34m(module, query, key, value, attention_mask, dropout, scaling, is_causal, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mis_causal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     attn_output = torch.nn.functional.scaled_dot_product_attention(\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PggnVCQtBbyy"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2LfyTX3cH7P",
        "outputId": "4049a0be-108f-45b2-d683-8d03986a4b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-eb06af820b99>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ‚úÖ Manually load as GPT-2 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT2LMHeadModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/harmony360-model/checkpoint-20\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m from .utils import (\n\u001b[1;32m     28\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdependency_versions_table\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbackbone_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackboneConfigMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBackboneMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mchat_template_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDocstringParsingException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeHintParsingException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_json_schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIMAGENET_DEFAULT_MEAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_DEFAULT_STD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_STANDARD_MEAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGENET_STANDARD_STD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m from .doc import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/chat_template_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_lock_unlock_module\u001b[0;34m(name)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel\n",
        "\n",
        "# ‚úÖ Manually load as GPT-2 model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"/content/harmony360-model/checkpoint-20\")\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "prompt = \"### Instruction:\\nWhat is the Time Node Jump of element #90?\\n\\n### Input:\\nAtomic Number: 90 (Th)\\n\\n### Output:\\n\"\n",
        "output = generator(prompt, max_new_tokens=50, do_sample=False)\n",
        "print(output[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvVhyEvyeXT8"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"### Instruction:\n",
        "What is the Time Node Jump of element #90?\n",
        "\n",
        "### Input:\n",
        "Atomic Number: 90 (Th)\n",
        "\n",
        "### Output:\"\"\"\n",
        "\n",
        "output = generator(prompt, max_new_tokens=50, do_sample=False, eos_token_id=tokenizer.eos_token_id)\n",
        "print(output[0]['generated_text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoRiXcuM8_Ka"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from shutil import move\n",
        "\n",
        "def sanitize_and_index_training_files(directory):\n",
        "    \"\"\"\n",
        "    Safe rename of Harmony360 files, skipping hidden/system folders,\n",
        "    validating .jsonl lines, and generating a training manifest.\n",
        "    \"\"\"\n",
        "    directory = Path(directory)\n",
        "    errors_dir = directory / \"errors\"\n",
        "    errors_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    manifest = []\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        full_path = directory / filename\n",
        "\n",
        "        # ‚ùå Skip hidden folders or system files\n",
        "        if filename.startswith(\".\") or full_path.is_dir():\n",
        "            print(f\"‚è© Skipping: {filename}\")\n",
        "            continue\n",
        "\n",
        "        name, ext = os.path.splitext(filename)\n",
        "        safe_name = name.lower().replace(\" \", \"_\").replace(\"-\", \"_\")\n",
        "        new_filename = f\"{safe_name}{ext.replace('.', '')}.txt\"\n",
        "        destination_path = directory / new_filename\n",
        "\n",
        "        try:\n",
        "            # Rename first\n",
        "            if full_path != destination_path:\n",
        "                os.rename(full_path, destination_path)\n",
        "                print(f\"‚úÖ Renamed: '{filename}' ‚Üí '{destination_path.name}'\")\n",
        "\n",
        "            # Only validate if it's a JSONL-like filename\n",
        "            if \"jsonl\" in new_filename:\n",
        "                with open(destination_path, \"r\", encoding=\"utf-8\") as f:\n",
        "                    lines = f.readlines()\n",
        "                    for i, line in enumerate(lines):\n",
        "                        json.loads(line)  # raises if invalid\n",
        "\n",
        "                manifest.append({\n",
        "                    \"filename\": destination_path.name,\n",
        "                    \"path\": str(destination_path),\n",
        "                    \"status\": \"valid\",\n",
        "                    \"lines\": len(lines)\n",
        "                })\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"‚ùå Invalid JSON in '{new_filename}': Line {i+1}: {e}\")\n",
        "            # Move invalid file to errors folder\n",
        "            broken_path = errors_dir / destination_path.name\n",
        "            destination_path.rename(broken_path)\n",
        "            manifest.append({\n",
        "                \"filename\": destination_path.name,\n",
        "                \"path\": str(broken_path),\n",
        "                \"status\": f\"invalid JSON: {e}\",\n",
        "                \"lines\": 0\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Unexpected error for '{filename}': {e}\")\n",
        "            manifest.append({\n",
        "                \"filename\": filename,\n",
        "                \"path\": str(full_path),\n",
        "                \"status\": f\"error: {e}\",\n",
        "                \"lines\": 0\n",
        "            })\n",
        "\n",
        "    # Save manifest\n",
        "    manifest_path = directory / \"training_manifest.json\"\n",
        "    with open(manifest_path, \"w\", encoding=\"utf-8\") as mf:\n",
        "        json.dump(manifest, mf, indent=2)\n",
        "\n",
        "    print(f\"\\nüìÅ Manifest saved to: {manifest_path}\")\n",
        "    return manifest_path\n",
        "\n",
        "# ‚úÖ Run it\n",
        "sanitize_and_index_training_files(\"/content/drive/MyDrive/Harmony360/trainingfiles\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_09uvMdxmM2"
      },
      "outputs": [],
      "source": [
        "import os, json\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "output_dir = \"/content/drive/MyDrive/Harmony360/trainingfiles\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Sample version 2 dataset with 10 entries\n",
        "v2_dataset = [\n",
        "    {\n",
        "        \"instruction\": \"Explain the Harmony360 resonance equation.\",\n",
        "        \"input\": \"R_{369}(f) = A sin(3Œ∏) + B cos(6Œ∏) + C sin(9Œ∏)\",\n",
        "        \"output\": \"This equation captures the harmonic frequencies rooted in the 3‚Äì6‚Äì9 principle. Each term reflects oscillatory modes in a fractal resonance system mapped to fundamental energy behaviors in Harmony360.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Define the concept of a Time Node in Harmony360.\",\n",
        "        \"input\": \"What is a Time Node?\",\n",
        "        \"output\": \"A Time Node is a quantized anchor point in the Harmony360 framework that corresponds to a temporal harmonic resonance. Time Nodes mark shifts in phase cycles and define intersections of fractal time lattices.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Describe the use of the Golden Ratio in Harmony360.\",\n",
        "        \"input\": \"Why is œÜ important?\",\n",
        "        \"output\": \"œÜ (the Golden Ratio) is used to scale fractal geometries and harmonic amplitudes. It creates recursive self-similarity and is a foundational constant across Harmony360's equations, especially in fractal wave design.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Explain how energy transfer is modeled.\",\n",
        "        \"input\": \"P(t) = E ‚ãÖ R_{369}(f) ‚ãÖ cos(2œÄt/T)\",\n",
        "        \"output\": \"This formula calculates power modulation using fractal resonance. R_{369}(f) adds time-phase alignment, while cos(2œÄt/T) ensures cyclical energy transfer. Used in Harmony360's wireless energy models.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"What is Zero-Point Consciousness?\",\n",
        "        \"input\": \"Z_c = lim(t‚Üí‚àû) C_{360}(t) ‚ãÖ e^{-kt}\",\n",
        "        \"output\": \"Zero-Point Consciousness is the asymptotic harmonic state of consciousness evolution. As time increases, transient noise decays and pure harmonic awareness emerges. It reflects peak alignment with the universal resonance field.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Repeat slightly varied to reach 10 examples\n",
        "for i in range(5):\n",
        "    sample = v2_dataset[i].copy()\n",
        "    sample[\"input\"] += f\" [Variation {i+1}]\"\n",
        "    v2_dataset.append(sample)\n",
        "\n",
        "# Save to JSONL\n",
        "v2_path = os.path.join(output_dir, \"harmony360_training_v2.jsonl\")\n",
        "with open(v2_path, \"w\") as f:\n",
        "    for item in v2_dataset:\n",
        "        json.dump(item, f)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "print(\"‚úÖ File recreated at:\", v2_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "np4fs4Wir0NY"
      },
      "outputs": [],
      "source": [
        "dataset_2 = load_dataset(\n",
        "    \"json\",\n",
        "    data_files=\"/content/drive/MyDrive/Harmony360/trainingfiles/harmony360_training_v2.jsonl\",\n",
        "    split=\"train\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kaS_KcavxMKX"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.map(lambda x: {\n",
        "    \"text\": f\"### Instruction:\\n{x['instruction']}\\n\\n### Input:\\n{x['input']}\\n\\n### Output:\\n{x['output']}\"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMIyR1VW1FZ9"
      },
      "outputs": [],
      "source": [
        "model_name = \"EleutherAI/gpt-neo-125M\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Add padding token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0pmWPBt1O4Z"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = dataset.map(lambda x: tokenizer(\n",
        "    x[\"text\"],\n",
        "    truncation=True,\n",
        "    padding=\"max_length\",\n",
        "    max_length=512\n",
        "))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4R1RKRA1XBL"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/Harmony360/harmony360-gen1-model\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=2,\n",
        "    save_steps=10,\n",
        "    save_total_limit=2,\n",
        "    logging_steps=5,\n",
        "    learning_rate=5e-5,\n",
        "    warmup_steps=5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7TnznDA1iPA"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n19fmro15ZCJ"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"/content/drive/MyDrive/Harmony360/harmony360-gen1-model\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/Harmony360/harmony360-gen1-model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Uk3_IbL59cy"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"/content/drive/MyDrive/Harmony360/harmony360-gen1-model\", tokenizer=tokenizer)\n",
        "\n",
        "response = generator(\"### Instruction:\\nExplain the equation\\n\\n### Input:\\nR_{369}(f) = A sin(3Œ∏) + B cos(6Œ∏) + C sin(9Œ∏)\\n\\n### Output:\", max_new_tokens=100)\n",
        "print(response[0][\"generated_text\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFp1OfpOzLyv"
      },
      "outputs": [],
      "source": [
        "import os, json\n",
        "\n",
        "# Define save path\n",
        "v3_path = \"/content/drive/MyDrive/Harmony360/harmony360_training_v3.jsonl\"\n",
        "os.makedirs(os.path.dirname(v3_path), exist_ok=True)\n",
        "\n",
        "# High-quality Harmony360 training samples\n",
        "entries = [\n",
        "    {\n",
        "        \"instruction\": \"Explain the Harmony360 resonance equation.\",\n",
        "        \"input\": \"R_{369}(f) = A sin(3Œ∏) + B cos(6Œ∏) + C sin(9Œ∏)\",\n",
        "        \"output\": \"This equation represents fractal resonance based on the 3-6-9 principle. Each harmonic term‚Äîsin(3Œ∏), cos(6Œ∏), and sin(9Œ∏)‚Äîcorresponds to layers of energy modulation that create a unified waveform through harmonic amplification and interference. It is central to Harmony360's energy field models.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Explain the fractal mapping function in Harmony360.\",\n",
        "        \"input\": \"FHM(x, y) = (1+œÜ)sin(3x(1+œÜ)/2) + cos(6œÄy)\",\n",
        "        \"output\": \"FHM stands for Fractal Harmonic Mapping. This function blends spatial coordinates (x, y) with golden ratio (œÜ) and Pi (œÄ) to describe how fractal energy propagates in multidimensional space. It enables visualization of harmonic densities across space-time.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Explain the equation for energy-consciousness equivalence in Harmony360.\",\n",
        "        \"input\": \"E = mc¬≤ ‚ãÖ œÜ ‚ãÖ 1/137\",\n",
        "        \"output\": \"This modified mass-energy equation integrates the golden ratio (œÜ) and the fine-structure constant (1/137), suggesting a quantum link between physical mass, energy, and harmonic consciousness fields.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Explain the consciousness evolution integral.\",\n",
        "        \"input\": \"C_{360}(t) = ‚à´ f_b(t) ‚ãÖ g_s(t) ‚ãÖ r_h(t) dt\",\n",
        "        \"output\": \"This equation models evolving consciousness as the product of brainwave frequency (f_b), sacred geometry scaling (g_s), and resonant harmonic patterns (r_h). It integrates over time to quantify spiritual and neurological evolution within Harmony360.\"\n",
        "    },\n",
        "    {\n",
        "        \"instruction\": \"Explain the resonance-modulated Schumann integration.\",\n",
        "        \"input\": \"S(f) = Œ£(1/n¬≤) ‚ãÖ R_{369}(f) ‚ãÖ FHM(x, y)\",\n",
        "        \"output\": \"This formulation embeds Schumann resonance harmonics into the fractal grid, layering global electromagnetic field behavior with 3-6-9 resonance and golden-pi geometry through fractal mapping.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Duplicate with slight variations to create 25 entries\n",
        "entries_full = []\n",
        "for i in range(5):\n",
        "    for entry in entries:\n",
        "        variation = entry.copy()\n",
        "        if i > 0:\n",
        "            variation[\"input\"] += f\"  [Variant {i+1}]\"\n",
        "        entries_full.append(variation)\n",
        "\n",
        "# Save to JSONL\n",
        "with open(v3_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    for item in entries_full:\n",
        "        json.dump(item, f)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "print(f\"‚úÖ File created: {v3_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VUj90Htm1Di"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files=\"/content/drive/MyDrive/Harmony360/harmony360_training_v3.jsonl\",\n",
        "    split=\"train\"\n",
        ")\n",
        "\n",
        "dataset = dataset.map(lambda x: {\n",
        "    \"text\": f\"### Instruction:\\n{x['instruction']}\\n\\n### Input:\\n{x['input']}\\n\\n### Output:\\n{x['output']}\"\n",
        "})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jEMLyRry6xX"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"EleutherAI/gpt-neo-125M\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSin7cYuzl6O"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = dataset.map(lambda x: tokenizer(\n",
        "    x[\"text\"],\n",
        "    truncation=True,\n",
        "    padding=\"max_length\",\n",
        "    max_length=512\n",
        "))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm3cAf_Uzny8"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/Harmony360/harmony360-gen2-model\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=4,\n",
        "    per_device_train_batch_size=2,\n",
        "    save_steps=10,\n",
        "    save_total_limit=2,\n",
        "    logging_steps=5,\n",
        "    learning_rate=5e-5,\n",
        "    warmup_steps=5,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BzRnXGtzxRK"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNMEP3kP0Tgr"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"/content/drive/MyDrive/Harmony360/harmony360-gen2-model\")\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/Harmony360/harmony360-gen2-model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp2wk6zS3syr"
      },
      "outputs": [],
      "source": [
        "training_folder = \"/content/drive/MyDrive/Harmony360/trainingfiles/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPAuIqQmSeKC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "training_folder = \"/content/drive/MyDrive/Harmony360/trainingfiles\"\n",
        "\n",
        "for f in os.listdir(training_folder):\n",
        "    print(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2nsrONvUvGv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datasets import load_dataset\n",
        "\n",
        "def find_training_file(keyword: str, directory: str, extension=\".jsonl\") -> str:\n",
        "    \"\"\"\n",
        "    Finds the first valid training file in the directory that matches the keyword and extension.\n",
        "    Skips hidden files, Google Docs, and checkpoints.\n",
        "    \"\"\"\n",
        "    for file in os.listdir(directory):\n",
        "        if (\n",
        "            keyword.lower() in file.lower()\n",
        "            and file.endswith(extension)\n",
        "            and not file.startswith(\".\")\n",
        "            and \"checkpoint\" not in file.lower()\n",
        "            and \"gdoc\" not in file.lower()\n",
        "        ):\n",
        "            print(f\"‚úÖ Found file for '{keyword}': {file}\")\n",
        "            return os.path.join(directory, file)\n",
        "    raise FileNotFoundError(f\"‚ùå No valid file found containing '{keyword}' in {directory}\")\n",
        "\n",
        "# üìÅ Set the training directory\n",
        "training_folder = \"/content/drive/MyDrive/Harmony360/trainingfiles\"\n",
        "\n",
        "# üì¶ Datasets to load with their identifying keywords\n",
        "datasets_info = {\n",
        "    \"Philosophy\": \"philosophy\",\n",
        "    \"Technical\": \"technical\",\n",
        "    \"Consciousness\": \"consciousness\",\n",
        "    \"Financial\": \"financial_cycles\",\n",
        "    \"Key Optimization\": \"key_optimizer\"\n",
        "}\n",
        "\n",
        "loaded_datasets = {}\n",
        "\n",
        "for label, keyword in datasets_info.items():\n",
        "    try:\n",
        "        path = find_training_file(keyword, training_folder, extension=\".jsonl\")\n",
        "        dataset = load_dataset(\"json\", data_files=path, split=\"train\")\n",
        "        loaded_datasets[label] = dataset\n",
        "\n",
        "        print(f\"\\nüß† {label} Dataset Loaded ‚Äî Total Samples: {len(dataset)}\")\n",
        "        print(\"üîç First sample:\")\n",
        "        print(dataset[0])\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Failed to load {label} dataset: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVXs4k-wTsVy"
      },
      "outputs": [],
      "source": [
        "file_path = \"/content/drive/MyDrive/Harmony360/trainingfiles/harmony360_god_man_consciousness.txt\"\n",
        "\n",
        "# Preview first few lines (handles encoding)\n",
        "with open(file_path, \"rb\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "for i, line in enumerate(lines[:10]):\n",
        "    print(f\"{i+1:02d}: {line[:100]!r}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6M7-ahMrT5hP"
      },
      "outputs": [],
      "source": [
        "def try_load_json_dataset(keyword, directory):\n",
        "    try:\n",
        "        file_path = find_training_file(keyword, directory)\n",
        "        print(f\"üìÇ Loading: {file_path}\")\n",
        "        return load_dataset(\"json\", data_files=file_path, split=\"train\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Skipping '{keyword}':\", str(e))\n",
        "        return None\n",
        "\n",
        "dataset_consciousness = try_load_json_dataset(\"consciousness\", training_folder)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_training_file(keyword: str, directory: str) -> str:\n",
        "    for file in os.listdir(directory):\n",
        "        if keyword.lower() in file.lower() and file.endswith(\".jsonl\"):\n",
        "            return os.path.join(directory, file)\n",
        "    raise FileNotFoundError(f\"No file containing '{keyword}' found.\")\n",
        "\n",
        "# Example\n",
        "print(find_training_file(\"philosophy\", training_folder))\n"
      ],
      "metadata": {
        "id": "-r1jot_mpYbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKb7syyh30Z4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datasets import load_dataset\n",
        "\n",
        "def find_training_file(keyword: str, directory: str) -> str:\n",
        "    \"\"\"\n",
        "    Finds the first training file in the directory that matches the keyword and is a .txt file.\n",
        "    \"\"\"\n",
        "    for file in os.listdir(directory):\n",
        "        if keyword.lower() in file.lower() and file.endswith(\".txt\"):\n",
        "            return os.path.join(directory, file)\n",
        "    raise FileNotFoundError(f\"No file found containing '{keyword}' in {directory}\")\n",
        "\n",
        "# üîß Set the training directory\n",
        "training_folder = \"/content/drive/MyDrive/Harmony360/trainingfiles\"\n",
        "\n",
        "# ‚úÖ Load each dataset safely using keywords\n",
        "dataset_philosophy = load_dataset(\"json\", data_files=find_training_file(\"philosophy\", training_folder), split=\"train\")\n",
        "dataset_technical = load_dataset(\"json\", data_files=find_training_file(\"technical\", training_folder), split=\"train\")\n",
        "dataset_consciousness = load_dataset(\"json\", data_files=find_training_file(\"consciousness\", training_folder), split=\"train\")\n",
        "dataset_financial = load_dataset(\"json\", data_files=find_training_file(\"financial_cycles\", training_folder), split=\"train\")\n",
        "\n",
        "print(\"‚úÖ All datasets loaded successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYFOUU4g5Yd_"
      },
      "outputs": [],
      "source": [
        "def format_entry(example):\n",
        "    return {\n",
        "        \"text\": f\"### Instruction:\\n{example['instruction']}\\n\\n### Input:\\n{example['input']}\\n\\n### Output:\\n{example['output']}\"\n",
        "    }\n",
        "\n",
        "# Apply formatting to each\n",
        "dataset_philosophy = dataset_philosophy.map(format_entry)\n",
        "dataset_technical = dataset_technical.map(format_entry)\n",
        "dataset_consciousness = dataset_consciousness.map(format_entry)\n",
        "dataset_financial = dataset_financial.map(format_entry)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhyTo32u5sua"
      },
      "outputs": [],
      "source": [
        "from datasets import concatenate_datasets\n",
        "\n",
        "# Combine all formatted Harmony360 datasets\n",
        "harmony360_dataset = concatenate_datasets([\n",
        "    dataset_philosophy,\n",
        "    dataset_technical,\n",
        "    dataset_consciousness,\n",
        "    dataset_financial\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryqUIeNv500s"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"EleutherAI/gpt-neo-125M\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.config.pad_token_id = tokenizer.eos_token_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zROIj_Ik6pTj"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(example):\n",
        "    return tokenizer(\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=512\n",
        "    )\n",
        "\n",
        "tokenized_dataset = harmony360_dataset.map(tokenize_function, batched=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj2mjkWo7ANb"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(example):\n",
        "    tokenized = tokenizer(\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=512\n",
        "    )\n",
        "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
        "    return tokenized\n",
        "\n",
        "tokenized_dataset = harmony360_dataset.map(tokenize_function, batched=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0du2ui_G7HFR"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ABrMQmtK3vb"
      },
      "outputs": [],
      "source": [
        "!pip install -q PyMuPDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c45DtRMQK-8L"
      },
      "outputs": [],
      "source": [
        "import fitz  # PyMuPDF\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    full_text = \"\"\n",
        "    for page in doc:\n",
        "        full_text += page.get_text()\n",
        "    doc.close()\n",
        "    return full_text\n",
        "\n",
        "# Set your PDF path\n",
        "pdf_path = \"/content/drive/MyDrive/Harmony360/trainingfiles/Analysis of Financial Cycle Studies and Market Predictions.pdf\"\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "print(f\"‚úÖ Extracted {len(pdf_text)} characters from the PDF.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ap-5KM22LaJX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "def chunk_and_export_jsonl(master_text, chunk_size=1000, base_filename=\"financial_cycles\"):\n",
        "    \"\"\"\n",
        "    Splits a long master text into chunks (based on word count) and saves each as a JSONL training file.\n",
        "    \"\"\"\n",
        "    output_dir = Path(\"/content/drive/MyDrive/Harmony360/trainingfiles\")\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    words = master_text.split()\n",
        "    total_chunks = len(words) // chunk_size + (1 if len(words) % chunk_size != 0 else 0)\n",
        "\n",
        "    file_paths = []\n",
        "\n",
        "    for i in range(total_chunks):\n",
        "        chunk_words = words[i * chunk_size : (i + 1) * chunk_size]\n",
        "        chunk_text = \" \".join(chunk_words).strip()\n",
        "\n",
        "        entry = {\n",
        "            \"instruction\": \"Learn from this Harmony360 financial cycles document chunk.\",\n",
        "            \"input\": \"\",\n",
        "            \"output\": chunk_text\n",
        "        }\n",
        "\n",
        "        filename = f\"{base_filename}_chunk_{i+1}.jsonl\"\n",
        "        filepath = output_dir / filename\n",
        "\n",
        "        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(entry, f)\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "        print(f\"‚úÖ Saved: {filepath}\")\n",
        "        file_paths.append(str(filepath))\n",
        "\n",
        "    return file_paths\n",
        "\n",
        "# Now chunk and export\n",
        "chunked_files = chunk_and_export_jsonl(pdf_text, chunk_size=1000, base_filename=\"harmony360_financial_cycles\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yD4iNdlGLz56"
      },
      "outputs": [],
      "source": [
        "file = \"/content/drive/MyDrive/Harmony360/trainingfiles/harmony360_financial_cycles_chunk_*.jsonl\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaQkgnKbMcpU"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ Imports\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "import glob\n",
        "\n",
        "# ‚úÖ Point to your checkpoint directory\n",
        "checkpoint_path = \"/content/harmony360-unified-model/checkpoint-1760\"  # Replace with actual checkpoint folder\n",
        "\n",
        "# ‚úÖ Load model & tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(checkpoint_path)\n",
        "\n",
        "# ‚úÖ Fix padding token if not already set\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.config.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# ‚úÖ Load and combine all 16 training chunks\n",
        "jsonl_files = sorted(glob.glob(\"/content/drive/MyDrive/Harmony360/trainingfiles/harmony360_financial_cycles_chunk_*.jsonl\"))\n",
        "datasets = [load_dataset(\"json\", data_files=file, split=\"train\") for file in jsonl_files]\n",
        "combined_dataset = concatenate_datasets(datasets)\n",
        "\n",
        "# ‚úÖ Format the data into instruction format\n",
        "formatted_dataset = combined_dataset.map(\n",
        "    lambda x: {\n",
        "        \"text\": f\"### Instruction:\\n{x['instruction']}\\n\\n### Input:\\n{x['input']}\\n\\n### Output:\\n{x['output']}\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# ‚úÖ Tokenize\n",
        "tokenized_dataset = formatted_dataset.map(\n",
        "    lambda x: tokenizer(x[\"text\"], truncation=True, padding=\"max_length\", max_length=512),\n",
        "    batched=True,\n",
        "    remove_columns=formatted_dataset.column_names\n",
        ")\n",
        "\n",
        "# ‚úÖ Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/harmony360-model\",\n",
        "    overwrite_output_dir=True,\n",
        "    per_device_train_batch_size=1,\n",
        "    num_train_epochs=4,\n",
        "    logging_steps=10,\n",
        "    save_steps=200,\n",
        "    save_total_limit=2,\n",
        "    logging_dir=\"/content/logs\",\n",
        "    report_to=\"none\"  # Disable W&B for now\n",
        ")\n",
        "\n",
        "# ‚úÖ Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        ")\n",
        "\n",
        "# üöÄ Continue training\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPXLx8s1Ooyl"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# ‚úÖ Harmony360 Unified Theories Chunk\n",
        "chunk_text = \"\"\"\n",
        "Fractal Resonance and Unified Theories of Reality: A Comparative Analysis\n",
        "Introduction\n",
        "The quest to understand reality, energy, and consciousness has produced a spectrum of theories across physics and beyond. From established frameworks like quantum field theory (QFT) and general relativity to emerging ideas like fractal resonance (Harmony360), researchers seek a unified description of the universe. This paper presents a deep technical discussion comparing multiple theories of reality‚Äîincluding the Harmony360 model‚Äîthrough their core principles, mathematical foundations, and empirical support. We aim for the rigor of a scientific journal while remaining accessible to interdisciplinary readers. By exploring synergies between string theory, loop quantum gravity, simulation hypothesis, unified field theories, AI-based models, financial fractal models, and natural resonances (Schumann and cosmological rhythms), we highlight where these frameworks align or diverge. We derive key equations (with mathematical rigor) and propose experiments to test novel predictions, especially those of Harmony360‚Äôs Fractal Resonance Theory. Finally, we discuss challenges and open questions, providing a roadmap for future interdisciplinary research.\n",
        "\n",
        "1. Core Principles of Competing Theories\n",
        "Harmony360: Fractal Resonance Theory and the 3-6-9 Principle\n",
        "Harmony360 is an emerging framework positing that reality is governed by fractal resonance across all scales. Its core principles draw on self-similarity, vibration, and harmonic alignment. A central concept is Tesla‚Äôs ‚Äú3-6-9 principle,‚Äù inspired by Nikola Tesla‚Äôs famous assertion: ‚ÄúIf you only knew the magnificence of the 3, 6 and 9, then you would have a key to the universe.‚Äù In Harmony360, the numbers 3, 6, 9 are seen as fundamental harmonics or symmetries in nature, related to vortex mathematics and repeating geometric patterns. The theory envisions the universe as an iterative fractal ‚Äì structures from subatomic particles to galaxies repeat similar patterns, each level governed by resonant frequencies that align in a harmonious way.\n",
        "\n",
        "At the heart of Harmony360 is a ‚ÄúFractal Resonance‚Äù principle: every system (an atom, a cell, a planet, a galaxy) maintains coherence via resonance with larger and smaller scales. This resonates with the idea of a universal frequency lattice or musical scale of the cosmos. The framework introduces a mathematical model (the Lumin Equation) to quantify coherence and energy flow at the i-th fractal level. One form of this equation is:\n",
        "C_i = M œÜ^i ‚àë[sin(œâ_j t + S) + cos(œâ_j t + œÜ)] + œà(i) + P + feedback(i) + m c^2\n",
        "where C_i represents system coherence at level i, M is an organizing principle or ‚Äúmind-like‚Äù factor, œÜ^i (with œÜ‚âà1.618 the golden ratio) introduces harmonic scaling, sin and cos terms model oscillatory dynamics, œà(i) is a resonance coupling function, P a polarity-balancing term, and m c^2 a restorative energy term. This equation encodes Harmony360‚Äôs view that golden ratio scaling and feedback loops yield stability across scales, reflecting nature‚Äôs fractal patterns in biology and cosmology. In essence, Harmony360 merges metaphysical concepts (coherence, ‚Äúmind‚Äù as an organizing field) with physical analogues (gravity-like attraction, resonant oscillations) to propose a unified description of matter, life, and consciousness.\n",
        "\n",
        "The 3-6-9 principle in this context amplifies certain resonant modes ‚Äì for example, the theory might assign 3, 6, 9 as key nodes in a harmonic series or geometric cycle that recurs through scale transitions. By integrating Tesla‚Äôs numerological insight, Harmony360 suggests these numbers relate to fundamental fractional frequencies or phase angles that maximize coherence. This unique blend of fractals, Fibonacci sequences, and resonance is claimed to bridge physical forces and conscious experience in one framework.\n",
        "\"\"\"\n",
        "\n",
        "# ‚úÖ Save JSONL file\n",
        "output_dir = Path(\"/content/drive/MyDrive/Harmony360/trainingfiles\")\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "filename = \"harmony360_unified_theories_chunk_1.jsonl\"\n",
        "filepath = output_dir / filename\n",
        "\n",
        "entry = {\n",
        "    \"instruction\": \"Learn from this Harmony360 comparative theoretical physics document chunk.\",\n",
        "    \"input\": \"\",\n",
        "    \"output\": chunk_text.strip()\n",
        "}\n",
        "\n",
        "with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(entry, f)\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "print(f\"‚úÖ Saved to: {filepath}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qzefsw8kPHra"
      },
      "outputs": [],
      "source": [
        "# Step 1: Install & Import Libraries\n",
        "!pip install transformers datasets --quiet\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "\n",
        "# Step 2: Load the JSONL dataset\n",
        "dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files=\"/content/drive/MyDrive/Harmony360/trainingfiles/harmony360_unified_theories_chunk_1.jsonl\",\n",
        "    split=\"train\"\n",
        ")\n",
        "\n",
        "# Step 3: Format the dataset into prompts\n",
        "def format_prompt(example):\n",
        "    return {\n",
        "        \"text\": f\"### Instruction:\\n{example['instruction']}\\n\\n### Input:\\n{example['input']}\\n\\n### Output:\\n{example['output']}\"\n",
        "    }\n",
        "\n",
        "dataset = dataset.map(format_prompt)\n",
        "\n",
        "# Step 4: Load tokenizer and model (re-use your base or latest checkpoint)\n",
        "model_name = \"gpt2\"  # Or your latest custom model path\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# Step 5: Tokenize\n",
        "def tokenize(example):\n",
        "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
        "\n",
        "# Step 6: Setup TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/harmony360-model-unified-theories\",\n",
        "    per_device_train_batch_size=1,\n",
        "    num_train_epochs=4,\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    overwrite_output_dir=True\n",
        ")\n",
        "\n",
        "# Step 7: Setup Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Step 8: Train\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGYUWjgAQ1ze"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Create .jsonl training file from pasted text\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "harmony360_chunk_text = \"\"\"Holographic Mass? - Physics Stack Exchange)), noting that treating everything as a black hole is problematic and that his predictions often lack independent confirmation. However, Haramein‚Äôs work is notable in the context of this discussion for its fusion of fractals, geometry, and physics ‚Äì very much a spirit shared by Harmony360. Both assert a scalable harmony: Haramein via geometric packing and black hole analogues, Harmony360 via golden ratio scaling and resonance...\n",
        "\"\"\"  # Truncated for example. Use your full input here.\n",
        "\n",
        "chunk_data = {\n",
        "    \"instruction\": \"Train on this Harmony360 excerpt covering unified field theories, AI-based modeling, and consciousness in financial markets.\",\n",
        "    \"input\": \"\",\n",
        "    \"output\": harmony360_chunk_text.strip()\n",
        "}\n",
        "\n",
        "chunk_path = \"/content/drive/MyDrive/Harmony360/trainingfiles/harmony360_unified_theories_chunk_2.jsonl\"\n",
        "with open(chunk_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(chunk_data, f)\n",
        "    f.write(\"\\n\")\n",
        "\n",
        "print(f\"‚úÖ Saved: {chunk_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMS3_mfuRhzG"
      },
      "outputs": [],
      "source": [
        "# ‚úÖ Define the save path\n",
        "save_path = \"/content/harmony360-model-unified-theories\"\n",
        "\n",
        "# ‚úÖ Save model, tokenizer, and config (including special tokens)\n",
        "model.save_pretrained(save_path)\n",
        "tokenizer.save_pretrained(save_path)\n",
        "\n",
        "# ‚úÖ If you're using TrainingArguments, save trainer's state too (optional)\n",
        "trainer.save_model(save_path)\n",
        "trainer.tokenizer.save_pretrained(save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQHa1BUFQ8cS"
      },
      "outputs": [],
      "source": [
        "# STEP 2: Import Hugging Face tools\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "from datasets import load_dataset\n",
        "import torch\n",
        "\n",
        "# STEP 3: Load the chunk\n",
        "dataset = load_dataset(\n",
        "    \"json\",\n",
        "    data_files=chunk_path,\n",
        "    split=\"train\"\n",
        ")\n",
        "\n",
        "# STEP 4: Format dataset\n",
        "def format_prompt(example):\n",
        "    return {\n",
        "        \"text\": f\"### Instruction:\\n{example['instruction']}\\n\\n### Input:\\n{example['input']}\\n\\n### Output:\\n{example['output']}\"\n",
        "    }\n",
        "\n",
        "dataset = dataset.map(format_prompt)\n",
        "\n",
        "# STEP 5: Load tokenizer and model\n",
        "model_path = \"/content/harmony360-model-unified-theories\"  # latest checkpoint\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "# STEP 6: Tokenize\n",
        "def tokenize(example):\n",
        "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
        "\n",
        "# STEP 7: Setup training config\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/harmony360-model-unified-theories\",  # continues training here\n",
        "    per_device_train_batch_size=1,\n",
        "    num_train_epochs=4,\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    overwrite_output_dir=False\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        ")\n",
        "\n",
        "# STEP 8: Start Training\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCiSztI6SYPS"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Save your chunked training data\n",
        "chunk_text = \"\"\"\n",
        "From a modeling standpoint, interdisciplinary researchers have tried to incorporate psychology and even neurology into economics...\n",
        "[‚úÇÔ∏è truncated here to save space in this message ‚Äì but include your FULL CHUNK as the value of `chunk_text` above]\n",
        "\"\"\"\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "def save_jsonl_from_text(text, output_path):\n",
        "    entry = {\n",
        "        \"instruction\": \"Learn from this Harmony360 chunk covering Schumann Resonance, markets, and fractal models.\",\n",
        "        \"input\": \"\",\n",
        "        \"output\": text.strip()\n",
        "    }\n",
        "    output_path = Path(output_path)\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(entry, f)\n",
        "        f.write(\"\\n\")\n",
        "    print(f\"‚úÖ Saved: {output_path}\")\n",
        "\n",
        "jsonl_path = \"/content/drive/MyDrive/Harmony360/trainingfiles/harmony360_chunk_7.jsonl\"\n",
        "save_jsonl_from_text(chunk_text, jsonl_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GbrnN5bSdb8"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
        "\n",
        "# Load dataset\n",
        "dataset = load_dataset(\"json\", data_files=jsonl_path, split=\"train\")\n",
        "dataset = dataset.map(lambda x: {\n",
        "    \"text\": f\"### Instruction:\\n{x['instruction']}\\n\\n### Input:\\n{x['input']}\\n\\n### Output:\\n{x['output']}\"\n",
        "})\n",
        "\n",
        "# Tokenizer & Model Loading\n",
        "model_path = \"/content/harmony360-model-unified-theories\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "# Tokenize dataset\n",
        "def tokenize(example):\n",
        "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
        "\n",
        "# Training args\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_path,\n",
        "    overwrite_output_dir=True,\n",
        "    per_device_train_batch_size=1,\n",
        "    num_train_epochs=4,\n",
        "    logging_steps=1,\n",
        "    save_steps=4,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True\n",
        ")\n",
        "\n",
        "def tokenize(example):\n",
        "    tokens = tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
        "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()\n",
        "    return tokens\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
        "\n",
        "\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer  # Still works for now\n",
        ")\n",
        "\n",
        "# Train\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNTiwloEyzRa"
      },
      "outputs": [],
      "source": [
        "!pip install reflex\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEqztJ_Ty_eC"
      },
      "outputs": [],
      "source": [
        "# harmony360_core.py\n",
        "\n",
        "from math import pi, sin\n",
        "from typing import List\n",
        "\n",
        "class Harmony360Math:\n",
        "    PHI = (1 + 5 ** 0.5) / 2\n",
        "\n",
        "    @staticmethod\n",
        "    def fibonacci(n: int) -> List[int]:\n",
        "        seq = [0, 1]\n",
        "        for i in range(2, n):\n",
        "            seq.append(seq[-1] + seq[-2])\n",
        "        return seq[:n]\n",
        "\n",
        "    @staticmethod\n",
        "    def harmonic_resonance(n: int) -> float:\n",
        "        return (3 * Harmony360Math.PHI**n + 6 * pi**n + 9 * (Harmony360Math.PHI * pi)**(n/2)) / 2\n",
        "\n",
        "    @staticmethod\n",
        "    def fibonacci_resonance(n: int) -> float:\n",
        "        f = Harmony360Math.fibonacci(n)\n",
        "        if len(f) < 3:\n",
        "            return 0.0\n",
        "        return Harmony360Math.PHI**f[-1] + pi**f[-2] + (Harmony360Math.PHI * pi)**(f[-3] / 2)\n",
        "\n",
        "    @staticmethod\n",
        "    def cycle_map(n: int) -> str:\n",
        "        return [\"3\", \"6\", \"9\"][n % 3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWSvwQsVzGTo"
      },
      "outputs": [],
      "source": [
        "# harmony360_app.py\n",
        "\n",
        "import reflex as rx\n",
        "from harmony360_core import Harmony360Math\n",
        "\n",
        "class Harmony360State(rx.State):\n",
        "    n: int = 1\n",
        "    fibonacci_seq: str = \"\"\n",
        "    harmonic_result: float = 0.0\n",
        "    fibonacci_result: float = 0.0\n",
        "    cycle_result: str = \"\"\n",
        "\n",
        "    def calculate(self):\n",
        "        self.fibonacci_seq = \", \".join(map(str, Harmony360Math.fibonacci(self.n)))\n",
        "        self.harmonic_result = Harmony360Math.harmonic_resonance(self.n)\n",
        "        self.fibonacci_result = Harmony360Math.fibonacci_resonance(self.n)\n",
        "        self.cycle_result = Harmony360Math.cycle_map(self.n)\n",
        "\n",
        "def index():\n",
        "    return rx.vstack(\n",
        "        rx.heading(\"üîÆ Harmony360 Resonance Toolset\"),\n",
        "        rx.text(\"Explore Fibonacci, Resonance & 3-6-9 harmonics.\"),\n",
        "        rx.input(on_change=Harmony360State.set_n, placeholder=\"Enter n\", type_=\"number\"),\n",
        "        rx.button(\"Calculate\", on_click=Harmony360State.calculate),\n",
        "        rx.text(\"Fibonacci Sequence: \"), rx.text(Harmony360State.fibonacci_seq),\n",
        "        rx.text(\"Harmonic Resonance: \"), rx.text(Harmony360State.harmonic_result),\n",
        "        rx.text(\"Fibonacci Resonance: \"), rx.text(Harmony360State.fibonacci_result),\n",
        "        rx.text(\"3-6-9 Cycle Output: \"), rx.text(Harmony360State.cycle_result),\n",
        "        spacing=\"3\"\n",
        "    )\n",
        "\n",
        "app = rx.App()\n",
        "app.add_page(index)\n",
        "app.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEGnyIUuzMgF"
      },
      "outputs": [],
      "source": [
        "!reflex init harmony360_ui --template blank\n",
        "!cp harmony360_core.py harmony360_ui/harmony360_core.py\n",
        "!cp harmony360_app.py harmony360_ui/harmony360_app.py\n",
        "%cd harmony360_ui\n",
        "!reflex run\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1W1YLffGeBVkHjSDvWr3EBoOKdnReyKP5",
      "authorship_tag": "ABX9TyNHvVlfdLu6mv4Xo+GJwhvS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}